# EMARAG-GraphRAG Environment Configuration
# Copy this file to .env and update with your actual values

# ===== LLM PROVIDER CONFIGURATION =====
# Choose at least one provider for conversational AI responses

# OpenAI API (Recommended for reliability)
OPENAI_API_KEY=your_openai_api_key_here
# Get key from: https://platform.openai.com/api-keys

# LM Studio (Local AI - Recommended for privacy)
LM_STUDIO_BASE_URL=http://localhost:1234
# Download LM Studio from: https://lmstudio.ai/

# OpenRouter (Multiple model access)
OPENROUTER_API_KEY=your_openrouter_api_key_here
# Get key from: https://openrouter.ai/keys

# ===== SYSTEM CONFIGURATION =====

# GPU Configuration (optional)
CUDA_VISIBLE_DEVICES=0
# Uncomment to specify which GPU to use (0 for first GPU)

# Processing Configuration
GRAPHRAG_MAX_THREADS=4
# Number of threads for GraphRAG processing

# ===== ADVANCED SETTINGS (Optional) =====

# Custom Model Override (optional)
# CUSTOM_LLM_MODEL=gpt-4o-mini
# CUSTOM_EMBEDDING_MODEL=text-embedding-3-small

# Local Model Paths (for advanced users)
# CLINICAL_BERT_PATH=/path/to/clinical/bert/model
# SPACY_MODEL_PATH=/path/to/spacy/model

# Logging Configuration
LOG_LEVEL=INFO
# Options: DEBUG, INFO, WARNING, ERROR

# ===== NOTES =====
# - At least one LLM provider API key is required for full functionality
# - LM Studio is free and runs locally (privacy-focused)
# - OpenAI provides reliable cloud-based models
# - OpenRouter offers access to multiple model providers
# - Clinical models will be downloaded automatically on first use
